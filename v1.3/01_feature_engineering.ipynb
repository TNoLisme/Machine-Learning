{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MALLORN TDE Classification v1.3 - Feature Engineering\n",
    "\n",
    "Giống như v1.2 - features của v1 + insights từ paper. Model ensemble sẽ có trong notebook 02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIR = Path('../mallorn-astronomical-classification-challenge')\n",
    "np.random.seed(42)\n",
    "\n",
    "BANDS = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "N_SPLITS = 20\n",
    "SNR_THRESHOLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3043, Test: 7135\n"
     ]
    }
   ],
   "source": [
    "train_log = pd.read_csv(DATA_DIR / 'train_log.csv')\n",
    "test_log = pd.read_csv(DATA_DIR / 'test_log.csv')\n",
    "print(f\"Train: {len(train_log)}, Test: {len(test_log)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_band_statistics(flux, flux_err, time):\n",
    "    n = len(flux)\n",
    "    if n == 0:\n",
    "        return {}\n",
    "    \n",
    "    snr = flux / (flux_err + 1e-10)\n",
    "    detections = snr > 3\n",
    "    n_det = np.sum(detections)\n",
    "    \n",
    "    feats = {\n",
    "        'n_obs': n, 'n_det': n_det, 'det_frac': n_det / n if n > 0 else 0,\n",
    "        'flux_mean': np.mean(flux), 'flux_std': np.std(flux), 'flux_median': np.median(flux),\n",
    "        'flux_max': np.max(flux), 'flux_min': np.min(flux), 'flux_range': np.max(flux) - np.min(flux),\n",
    "        'flux_iqr': np.percentile(flux, 75) - np.percentile(flux, 25),\n",
    "        'flux_skew': stats.skew(flux) if n > 2 else 0,\n",
    "        'flux_kurtosis': stats.kurtosis(flux) if n > 3 else 0,\n",
    "        'flux_p10': np.percentile(flux, 10), 'flux_p25': np.percentile(flux, 25),\n",
    "        'flux_p75': np.percentile(flux, 75), 'flux_p90': np.percentile(flux, 90),\n",
    "        'snr_mean': np.mean(snr), 'snr_max': np.max(snr), 'snr_median': np.median(snr), 'snr_std': np.std(snr),\n",
    "        'err_mean': np.mean(flux_err), 'err_std': np.std(flux_err),\n",
    "    }\n",
    "    \n",
    "    if n > 1:\n",
    "        feats['time_span'] = time[-1] - time[0]\n",
    "        feats['cadence_mean'] = np.mean(np.diff(time))\n",
    "        feats['cadence_std'] = np.std(np.diff(time))\n",
    "    else:\n",
    "        feats['time_span'] = feats['cadence_mean'] = feats['cadence_std'] = 0\n",
    "    \n",
    "    if n_det > 0:\n",
    "        det_flux = flux[detections]\n",
    "        det_time = time[detections]\n",
    "        feats['det_flux_mean'] = np.mean(det_flux)\n",
    "        feats['det_flux_max'] = np.max(det_flux)\n",
    "        feats['det_duration'] = det_time[-1] - det_time[0] if len(det_time) > 1 else 0\n",
    "        peak_idx = np.argmax(det_flux)\n",
    "        feats['peak_flux'] = det_flux[peak_idx]\n",
    "        feats['peak_time_rel'] = (det_time[peak_idx] - det_time[0]) / (feats['det_duration'] + 1) if feats['det_duration'] > 0 else 0.5\n",
    "        feats['_peak_time'] = det_time[peak_idx]\n",
    "        if peak_idx > 0:\n",
    "            rise_dt = det_time[peak_idx] - det_time[0]\n",
    "            feats['rise_time'] = rise_dt\n",
    "            feats['rise_rate'] = (det_flux[peak_idx] - det_flux[0]) / (rise_dt + 1e-10)\n",
    "        else:\n",
    "            feats['rise_time'] = feats['rise_rate'] = 0\n",
    "        if peak_idx < len(det_flux) - 1:\n",
    "            decay_dt = det_time[-1] - det_time[peak_idx]\n",
    "            feats['decay_time'] = decay_dt\n",
    "            feats['decay_rate'] = (det_flux[peak_idx] - det_flux[-1]) / (decay_dt + 1e-10)\n",
    "        else:\n",
    "            feats['decay_time'] = feats['decay_rate'] = 0\n",
    "        feats['variability'] = np.std(det_flux) / (np.mean(det_flux) + 1e-10) if len(det_flux) > 1 else 0\n",
    "        feats['rms'] = np.sqrt(np.mean(det_flux**2))\n",
    "    else:\n",
    "        for k in ['det_flux_mean','det_flux_max','det_duration','peak_flux','peak_time_rel','_peak_time',\n",
    "                  'rise_time','rise_rate','decay_time','decay_rate','variability','rms']:\n",
    "            feats[k] = 0\n",
    "    \n",
    "    feats['frac_above_mean'] = np.sum(flux > np.mean(flux)) / n\n",
    "    if n >= 3:\n",
    "        try:\n",
    "            slope, _, r_value, _, _ = stats.linregress(time, flux)\n",
    "            feats['trend_slope'] = slope\n",
    "            feats['trend_r2'] = r_value**2\n",
    "        except:\n",
    "            feats['trend_slope'] = feats['trend_r2'] = 0\n",
    "    else:\n",
    "        feats['trend_slope'] = feats['trend_r2'] = 0\n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_features(band_data):\n",
    "    colors = {}\n",
    "    band_fluxes = {}\n",
    "    band_peak_fluxes = {}\n",
    "    \n",
    "    for band in BANDS:\n",
    "        if band in band_data and len(band_data[band]['flux']) > 0:\n",
    "            flux = band_data[band]['flux']\n",
    "            snr = flux / (band_data[band]['flux_err'] + 1e-10)\n",
    "            det_mask = snr > 3\n",
    "            if np.sum(det_mask) > 0:\n",
    "                band_fluxes[band] = np.mean(flux[det_mask])\n",
    "                band_peak_fluxes[band] = np.max(flux[det_mask])\n",
    "            else:\n",
    "                band_fluxes[band] = np.mean(flux)\n",
    "                band_peak_fluxes[band] = np.max(flux)\n",
    "        else:\n",
    "            band_fluxes[band] = band_peak_fluxes[band] = 0\n",
    "    \n",
    "    for b1, b2 in [('u','g'),('u','r'),('u','i'),('g','r'),('g','i'),('r','i'),('i','z'),('z','y')]:\n",
    "        if band_fluxes[b1] > 0 and band_fluxes[b2] > 0:\n",
    "            colors[f'color_{b1}_{b2}'] = -2.5 * np.log10(band_fluxes[b1] / band_fluxes[b2])\n",
    "            colors[f'color_peak_{b1}_{b2}'] = -2.5 * np.log10((band_peak_fluxes[b1]+1e-10)/(band_peak_fluxes[b2]+1e-10))\n",
    "        else:\n",
    "            colors[f'color_{b1}_{b2}'] = colors[f'color_peak_{b1}_{b2}'] = 0\n",
    "    \n",
    "    blue_flux = band_fluxes['u'] + band_fluxes['g']\n",
    "    red_flux = sum([band_fluxes[b] for b in ['r','i','z','y']])\n",
    "    total = blue_flux + red_flux\n",
    "    \n",
    "    colors['blue_fraction'] = blue_flux / (total + 1e-10)\n",
    "    colors['u_fraction'] = band_fluxes['u'] / (total + 1e-10)\n",
    "    colors['g_fraction'] = band_fluxes['g'] / (total + 1e-10)\n",
    "    colors['blue_red_ratio'] = blue_flux / (red_flux + 1e-10)\n",
    "    colors['u_dominance'] = band_fluxes['u'] / (max(band_fluxes.values()) + 1e-10)\n",
    "    colors['peak_band_is_u'] = 1 if band_peak_fluxes['u'] == max(band_peak_fluxes.values()) else 0\n",
    "    colors['peak_band_is_g'] = 1 if band_peak_fluxes['g'] == max(band_peak_fluxes.values()) else 0\n",
    "    colors['peak_band_is_blue'] = 1 if max(band_peak_fluxes['u'],band_peak_fluxes['g']) >= max(band_peak_fluxes['r'],band_peak_fluxes['i'],band_peak_fluxes['z'],band_peak_fluxes['y']) else 0\n",
    "    \n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_temporal_features(band_data):\n",
    "    feats = {}\n",
    "    all_times, all_det_times = [], []\n",
    "    peak_times = {}\n",
    "    global_peak_time, global_peak_flux = None, 0\n",
    "    \n",
    "    for band in BANDS:\n",
    "        if band in band_data and len(band_data[band]['flux']) > 0:\n",
    "            flux, time, flux_err = band_data[band]['flux'], band_data[band]['time'], band_data[band]['flux_err']\n",
    "            all_times.extend(time)\n",
    "            snr = flux / (flux_err + 1e-10)\n",
    "            det_mask = snr > 3\n",
    "            if np.sum(det_mask) > 0:\n",
    "                det_time, det_flux = time[det_mask], flux[det_mask]\n",
    "                all_det_times.extend(det_time)\n",
    "                peak_idx = np.argmax(det_flux)\n",
    "                peak_times[band] = det_time[peak_idx]\n",
    "                if det_flux[peak_idx] > global_peak_flux:\n",
    "                    global_peak_flux = det_flux[peak_idx]\n",
    "                    global_peak_time = det_time[peak_idx]\n",
    "    \n",
    "    feats['total_time_span'] = max(all_times) - min(all_times) if all_times else 0\n",
    "    feats['total_observations'] = len(all_times)\n",
    "    feats['detection_time_span'] = max(all_det_times) - min(all_det_times) if all_det_times else 0\n",
    "    feats['total_detections'] = len(all_det_times)\n",
    "    \n",
    "    if len(peak_times) >= 2:\n",
    "        feats['peak_time_spread'] = max(peak_times.values()) - min(peak_times.values())\n",
    "        feats['peak_delay_u_r'] = peak_times.get('u',0) - peak_times.get('r',0) if 'u' in peak_times and 'r' in peak_times else 0\n",
    "        feats['peak_delay_g_r'] = peak_times.get('g',0) - peak_times.get('r',0) if 'g' in peak_times and 'r' in peak_times else 0\n",
    "    else:\n",
    "        feats['peak_time_spread'] = feats['peak_delay_u_r'] = feats['peak_delay_g_r'] = 0\n",
    "    \n",
    "    feats['n_bands_detected'] = sum([1 for b in BANDS if b in band_data and len(band_data[b]['flux'])>0 and np.sum(band_data[b]['flux']/(band_data[b]['flux_err']+1e-10)>3)>0])\n",
    "    feats['_global_peak_time'] = global_peak_time\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variability_features(band_data):\n",
    "    feats = {}\n",
    "    all_var = []\n",
    "    for band in BANDS:\n",
    "        if band in band_data and len(band_data[band]['flux']) > 2:\n",
    "            flux, time = band_data[band]['flux'], band_data[band]['time']\n",
    "            diffs = np.diff(flux)\n",
    "            feats[f'{band}_flux_diff_std'] = np.std(diffs)\n",
    "            feats[f'{band}_flux_diff_mean'] = np.mean(np.abs(diffs))\n",
    "            if len(flux) > 3:\n",
    "                try:\n",
    "                    coeffs = np.polyfit(range(len(flux)), flux[np.argsort(time)], 2)\n",
    "                    residuals = flux[np.argsort(time)] - np.polyval(coeffs, range(len(flux)))\n",
    "                    feats[f'{band}_residual_std'] = np.std(residuals)\n",
    "                except:\n",
    "                    feats[f'{band}_residual_std'] = 0\n",
    "            else:\n",
    "                feats[f'{band}_residual_std'] = 0\n",
    "            cv = np.std(flux) / (np.mean(np.abs(flux)) + 1e-10)\n",
    "            all_var.append(cv)\n",
    "            feats[f'{band}_cv'] = cv\n",
    "        else:\n",
    "            feats[f'{band}_flux_diff_std'] = feats[f'{band}_flux_diff_mean'] = feats[f'{band}_residual_std'] = feats[f'{band}_cv'] = 0\n",
    "    feats['mean_variability'] = np.mean(all_var) if all_var else 0\n",
    "    feats['max_variability'] = np.max(all_var) if all_var else 0\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paper_features(band_data, global_peak_time, redshift=0):\n",
    "    feats = {}\n",
    "    \n",
    "    if global_peak_time is not None and global_peak_time > 0:\n",
    "        n_det_pre, n_det_near, n_det_post = 0, 0, 0\n",
    "        bands_near_peak = set()\n",
    "        has_u_near = False\n",
    "        \n",
    "        for band in BANDS:\n",
    "            if band not in band_data: continue\n",
    "            flux, flux_err, time = band_data[band]['flux'], band_data[band]['flux_err'], band_data[band]['time']\n",
    "            det_mask = (flux / (flux_err + 1e-10)) > SNR_THRESHOLD\n",
    "            if np.sum(det_mask) == 0: continue\n",
    "            for t in time[det_mask]:\n",
    "                rel_t = t - global_peak_time\n",
    "                if rel_t < -10: n_det_pre += 1\n",
    "                elif -10 <= rel_t <= 10:\n",
    "                    n_det_near += 1\n",
    "                    bands_near_peak.add(band)\n",
    "                    if band == 'u': has_u_near = True\n",
    "                elif 10 < rel_t <= 30: n_det_post += 1\n",
    "        \n",
    "        feats['n_det_pre_peak'] = n_det_pre\n",
    "        feats['n_det_near_peak'] = n_det_near\n",
    "        feats['n_det_post_peak'] = n_det_post\n",
    "        feats['n_bands_near_peak'] = len(bands_near_peak)\n",
    "        feats['has_u_near_peak'] = 1 if has_u_near else 0\n",
    "        feats['some_color_score'] = ((1 if n_det_pre>=1 else 0) + (1 if len(bands_near_peak)>=3 else 0) + (1 if n_det_post>=2 else 0)) / 3.0\n",
    "    else:\n",
    "        for k in ['n_det_pre_peak','n_det_near_peak','n_det_post_peak','n_bands_near_peak','has_u_near_peak','some_color_score']:\n",
    "            feats[k] = 0\n",
    "    \n",
    "    z_factor = 1 + redshift if redshift > 0 else 1\n",
    "    u_flux = np.mean(band_data['u']['flux']) if 'u' in band_data and len(band_data['u']['flux'])>0 else 0\n",
    "    r_flux = np.mean(band_data['r']['flux']) if 'r' in band_data and len(band_data['r']['flux'])>0 else 0\n",
    "    feats['color_u_r_z_norm'] = (-2.5 * np.log10(u_flux / r_flux)) / z_factor if u_flux > 0 and r_flux > 0 else 0\n",
    "    \n",
    "    det_span = 0\n",
    "    for band in BANDS:\n",
    "        if band in band_data:\n",
    "            flux, flux_err, time = band_data[band]['flux'], band_data[band]['flux_err'], band_data[band]['time']\n",
    "            det_mask = (flux / (flux_err + 1e-10)) > 3\n",
    "            if np.sum(det_mask) > 1:\n",
    "                det_span = max(det_span, time[det_mask][-1] - time[det_mask][0])\n",
    "    feats['duration_class'] = 2 if det_span > 300 else (1 if det_span > 150 else 0)\n",
    "    \n",
    "    for band in ['g', 'r']:\n",
    "        if band in band_data and len(band_data[band]['flux']) > 4:\n",
    "            flux = band_data[band]['flux'][np.argsort(band_data[band]['time'])]\n",
    "            try:\n",
    "                feats[f'{band}_autocorr'] = np.corrcoef(flux[:-1], flux[1:])[0,1]\n",
    "                if np.isnan(feats[f'{band}_autocorr']): feats[f'{band}_autocorr'] = 0\n",
    "            except:\n",
    "                feats[f'{band}_autocorr'] = 0\n",
    "            diffs = np.diff(flux)\n",
    "            feats[f'{band}_sign_change_rate'] = np.sum(np.diff(np.sign(diffs))!=0)/(len(diffs)-1+1e-10) if len(flux)>2 else 0\n",
    "        else:\n",
    "            feats[f'{band}_autocorr'] = feats[f'{band}_sign_change_rate'] = 0\n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_object(obj_id, lc_df, redshift=0):\n",
    "    features = {'object_id': obj_id}\n",
    "    obj_data = lc_df[lc_df['object_id'] == obj_id]\n",
    "    if len(obj_data) == 0: return None\n",
    "    \n",
    "    band_data = {}\n",
    "    for band in BANDS:\n",
    "        band_df = obj_data[obj_data['Filter'] == band].sort_values('Time (MJD)')\n",
    "        if len(band_df) > 0:\n",
    "            band_data[band] = {'flux': band_df['Flux'].values, 'flux_err': band_df['Flux_err'].values, 'time': band_df['Time (MJD)'].values}\n",
    "    \n",
    "    for band in BANDS:\n",
    "        if band in band_data:\n",
    "            band_feats = extract_band_statistics(band_data[band]['flux'], band_data[band]['flux_err'], band_data[band]['time'])\n",
    "            for k, v in band_feats.items():\n",
    "                if not k.startswith('_'): features[f'{band}_{k}'] = v\n",
    "        else:\n",
    "            for k in ['n_obs','n_det','det_frac','flux_mean','flux_std','flux_median','flux_max','flux_min','flux_range',\n",
    "                     'flux_iqr','flux_skew','flux_kurtosis','flux_p10','flux_p25','flux_p75','flux_p90','snr_mean','snr_max',\n",
    "                     'snr_median','snr_std','err_mean','err_std','time_span','cadence_mean','cadence_std','det_flux_mean',\n",
    "                     'det_flux_max','det_duration','peak_flux','peak_time_rel','rise_time','rise_rate','decay_time','decay_rate',\n",
    "                     'variability','rms','frac_above_mean','trend_slope','trend_r2']:\n",
    "                features[f'{band}_{k}'] = 0\n",
    "    \n",
    "    features.update(extract_color_features(band_data))\n",
    "    temporal = extract_temporal_features(band_data)\n",
    "    gpt = temporal.pop('_global_peak_time', None)\n",
    "    features.update(temporal)\n",
    "    features.update(extract_variability_features(band_data))\n",
    "    features.update(extract_paper_features(band_data, gpt, redshift))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TRAINING data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_01: total 155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_02: total 325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_03: total 463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_04: total 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_05: total 773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_06: total 928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_07: total 1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_08: total 1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_09: total 1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_10: total 1527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_11: total 1673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_12: total 1828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_13: total 1971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_14: total 2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_15: total 2283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_16: total 2438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_17: total 2591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_18: total 2743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_19: total 2890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_20: total 3043\n",
      "Train features: 3043\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing TRAINING data...\")\n",
    "train_z = dict(zip(train_log['object_id'], train_log['Z']))\n",
    "train_ids = set(train_log['object_id'])\n",
    "train_features_list = []\n",
    "\n",
    "for split_num in range(1, N_SPLITS + 1):\n",
    "    lc_file = DATA_DIR / f'split_{split_num:02d}' / 'train_full_lightcurves.csv'\n",
    "    if not lc_file.exists(): continue\n",
    "    lc_df = pd.read_csv(lc_file)\n",
    "    obj_ids = [o for o in lc_df['object_id'].unique() if o in train_ids]\n",
    "    for obj_id in tqdm(obj_ids, desc=f\"split_{split_num:02d}\", leave=False):\n",
    "        feats = extract_features_for_object(obj_id, lc_df, train_z.get(obj_id, 0))\n",
    "        if feats: train_features_list.append(feats)\n",
    "    print(f\"  split_{split_num:02d}: total {len(train_features_list)}\")\n",
    "\n",
    "train_features = pd.DataFrame(train_features_list)\n",
    "print(f\"Train features: {len(train_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing TEST data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_01: total 364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_02: total 778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_03: total 1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_04: total 1448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_05: total 1823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_06: total 2197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_07: total 2595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_08: total 2982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_09: total 3271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_10: total 3602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_11: total 3927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_12: total 4280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_13: total 4659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_14: total 5010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_15: total 5352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_16: total 5706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_17: total 6057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_18: total 6402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_19: total 6777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  split_20: total 7135\n",
      "Test features: 7135\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nProcessing TEST data...\")\n",
    "test_z = dict(zip(test_log['object_id'], test_log['Z']))\n",
    "test_ids = set(test_log['object_id'])\n",
    "test_features_list = []\n",
    "\n",
    "for split_num in range(1, N_SPLITS + 1):\n",
    "    lc_file = DATA_DIR / f'split_{split_num:02d}' / 'test_full_lightcurves.csv'\n",
    "    if not lc_file.exists(): continue\n",
    "    lc_df = pd.read_csv(lc_file)\n",
    "    obj_ids = [o for o in lc_df['object_id'].unique() if o in test_ids]\n",
    "    for obj_id in tqdm(obj_ids, desc=f\"split_{split_num:02d}\", leave=False):\n",
    "        feats = extract_features_for_object(obj_id, lc_df, test_z.get(obj_id, 0))\n",
    "        if feats: test_features_list.append(feats)\n",
    "    print(f\"  split_{split_num:02d}: total {len(test_features_list)}\")\n",
    "\n",
    "test_features = pd.DataFrame(test_features_list)\n",
    "print(f\"Test features: {len(test_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: train (3043, 308), test (7135, 308)\n",
      "Next: 02_model_training.ipynb (ENSEMBLE)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nĐã lưu: train {train_features.shape}, test {test_features.shape}\")\n",
    "print(\"Tiếp theo: 02_model_training.ipynb (ENSEMBLE)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
